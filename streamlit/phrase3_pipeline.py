# -*- coding: utf-8 -*-
"""phrase3_pipeline

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1asl9sC_CkhHSkPsWSJ2qj1d36tUU6Jo9

# Learning Objectives

Once data is ingested (and potentially enriched or modified through GenAI tools within data pipelines, as discussed last week), data teams must leverage this data to deliver impactful data applications for stakeholders and customers. This involves further enrichment using advanced GenAI techniques.

In this class, we will explore:

- **Retrieval-Augmented Generation (RAG):** Incorporating domain-specific knowledge into LLMs without requiring fine-tuning.  
- **Reranking:** Optimizing search results for relevance and context.  
- **Text-to-SQL:** Automating the conversion of natural language queries into SQL commands.  
- **Function Calling:** Enabling LLMs to interact with APIs and external tools dynamically.
"""

# # easiest path, auth with your BU account that you are using on GCP
# from google.colab import auth
# auth.authenticate_user()

# imports
import pandas as pd
import numpy as np
import json

import streamlit as st
from google.cloud import bigquery

import vertexai
from vertexai.generative_models import GenerativeModel, ChatSession
from vertexai.generative_models import Part
from vertexai.generative_models import (
    Content,
    FunctionDeclaration,
    GenerationConfig,
    Tool,
    ToolConfig
)

st.title('CDC Database Text to SQL Tool')

# setup your project
project_id = "ba882-group-10" # my project is btibert-ba882-fall24
region_id = "us-central1" # my region is us-central1


# this uses google secret key here in Colab
# you will need to retrieve this from Pinecone to follow along
bq_client = bigquery.Client(project = project_id)

join_logic = """
SELECT *
FROM `ba882-group-10`.cdc_data.cdc_occurrences_staging AS o
JOIN `ba882-group-10`.cdc_data.disease_dic AS d
ON o.Disease = CAST(d.disease_code AS STRING)
JOIN `ba882-group-10`.cdc_data.symptom AS s
ON o.Disease = s.Disease
JOIN `ba882-group-10`.demographic_data.census_data AS c
ON o.Region= c.State
"""

df = pd.read_gbq(join_logic, project_id='ba882-group-10')


sql_query1 = """
SELECT table_name, column_name, data_type
FROM `ba882-group-10.cdc_data.INFORMATION_SCHEMA.COLUMNS`
"""
sql_query2 = """
SELECT table_name, column_name, data_type
FROM `ba882-group-10.demographic_data.INFORMATION_SCHEMA.COLUMNS`
"""

schema_df1 = pd.read_gbq(sql_query1, project_id='ba882-group-10')
schema_df2 = pd.read_gbq(sql_query2, project_id='ba882-group-10')

schema_df = pd.concat([schema_df1, schema_df2], ignore_index=True)

schema_records = schema_df.to_dict(orient="records")


"""## Creating Prompts"""

model = GenerativeModel(model_name="gemini-1.5-flash-002")
generation_config=GenerationConfig(temperature=0)

# st.write('Enter your text below to see the SQL code')

user = st.text_input('Enter your text below to see the SQL code')


# prompts below
user= user
prompt = f"""
### System prompt
You are a sql expert.  For the user's input, generate a SQL prompt given the schema and join logic, and mega table context provided.
The data includes eight diseases and cases within the U.S., ranging from beginning of 2023 to now and it refreshes on a weekly basis.
You need to return valid JSON with a key SQL.  The value of the SQL key is the query to be
executed against the database.

Only use the table names and columns mentioned in the schema.
For aggregations, you need to ensure that you reference columns in the SELECT clause.
Some of the data types are wrong, so please use CAST for those columns.
Make sure your functions are compatible with BigQuery.

### Schema
{schema_records}

### Join Logic
{join_logic}

### Mega Table Context
{df}

### User prompt
{user}

### SQL prompt
"""


user_prompt_content = Content(
    role="user",
    parts=[
        Part.from_text(prompt),
    ],
)


# the response
response = model.generate_content(
    user_prompt_content,
    generation_config=generation_config,
)

response.text

#clean up the json to sql
cleaned_response = response.text.strip()

if cleaned_response.startswith('```json'):
    cleaned_response = cleaned_response.replace('```json', '').replace('```', '').strip()

# Step 2: Now, remove any additional escape characters
cleaned_response = cleaned_response.replace('\\', '')  # Remove escape slashes
cleaned_response = cleaned_response.replace('\n', '')  # Remove newlines

# Step 3: Parse the cleaned string as JSON
try:
    parsed_json = json.loads(cleaned_response)
    
    # Step 4: Extract the SQL query from the JSON
    sql_query = parsed_json.get('SQL')
    
    if sql_query:
        print("Generated SQL Query:")
        print(sql_query)
    else:
        print("Error: No 'SQL' key found in the response.")
        
except json.JSONDecodeError as e:
    print(f"Error decoding JSON: {e}")
    print("Cleaned response (unable to decode as JSON):")
    print(cleaned_response)

outcome= pd.read_gbq(sql_query)
st.write(outcome.head())
